## Diebold Mariano simulations
load("/Users/alexanderbech/Dropbox/Project/diebold_sim.RData")
DB.a.50 = sapply(1:50, function(i) MC.a.50[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.a.100 = sapply(1:50, function(i) MC.a.100[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.b.50 = sapply(1:50, function(i) MC.b.50[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.b.100 = sapply(1:50, function(i) MC.b.100[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.grid = c("OLS" = 1, "Ridge" = 2,
"Lasso" = 3, "ENET" = 4, "PCR"=5,
"PLSR"=6, "GLM" = 7, "RandomF" = 8,
"GBRT" = 9,
"Oracle"=10)
colnames(DB.a.50) = names(DB.grid)
rownames(DB.a.50) = names(DB.grid)
colnames(DB.a.100) = names(DB.grid)
rownames(DB.a.100) = names(DB.grid)
colnames(DB.b.50) = names(DB.grid)
rownames(DB.b.50) = names(DB.grid)
colnames(DB.b.100) = names(DB.grid)
rownames(DB.b.100) = names(DB.grid)
print(xtable(DB.a.50, type = "latex"), file = "DB.a.50.tex")
print(xtable(DB.a.100, type = "latex"), file = "DB.a.100.tex")
print(xtable(DB.b.50, type = "latex"), file = "DB.b.50.tex")
print(xtable(DB.b.100, type = "latex"), file = "DB.b.100.tex")
## Diebold Mariano simulations
library(tidyverse)
library(xtable)
load("/Users/alexanderbech/Dropbox/Project/diebold_sim.RData")
DB.a.50 = sapply(1:50, function(i) MC.a.50[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.a.100 = sapply(1:50, function(i) MC.a.100[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.b.50 = sapply(1:50, function(i) MC.b.50[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.b.100 = sapply(1:50, function(i) MC.b.100[[i]]$`Diebold Mariano test`) %>%
rowMeans() %>% matrix(.,nrow = 10)
DB.grid = c("OLS" = 1, "Ridge" = 2,
"Lasso" = 3, "ENET" = 4, "PCR"=5,
"PLSR"=6, "GLM" = 7, "RandomF" = 8,
"GBRT" = 9,
"Oracle"=10)
colnames(DB.a.50) = names(DB.grid)
rownames(DB.a.50) = names(DB.grid)
colnames(DB.a.100) = names(DB.grid)
rownames(DB.a.100) = names(DB.grid)
colnames(DB.b.50) = names(DB.grid)
rownames(DB.b.50) = names(DB.grid)
colnames(DB.b.100) = names(DB.grid)
rownames(DB.b.100) = names(DB.grid)
print(xtable(DB.a.50, type = "latex"), file = "DB.a.50.tex")
print(xtable(DB.a.100, type = "latex"), file = "DB.a.100.tex")
print(xtable(DB.b.50, type = "latex"), file = "DB.b.50.tex")
print(xtable(DB.b.100, type = "latex"), file = "DB.b.100.tex")
getwd()
DB.b.100
library(reshape2)
library(tidyverse)
library(abind)
library(glmnet)
library(pls)
library(lars)
library(mvtnorm)
library(gglasso)
library(splines)
library(leaps)
library(lubridate)
library(tree)
library(randomForest)
library(gbm)
library(Hmisc)
library(sandwich)
rm(list=ls())
library(readxl)
## Using PredictorData2017 from Amit Goyals' website (University of lausanne)
## data is from paper ("http://www.hec.unil.ch/agoyal/")
## "A Comprehensive Look at The Empirical Performance of Equity Premium Prediction"
## Data is updated up to 2017
monthly <-
read_excel("~/Dropbox/Project/PredictorData2017.xlsx" , sheet = "Monthly",
na = "NaN")
quart <-
read_excel("~/Dropbox/Project/PredictorData2017.xlsx" ,
sheet = "Quarterly",
na = "NaN")
annual <-
read_excel("~/Dropbox/Project/PredictorData2017.xlsx" , sheet = "Annual",
na = "NaN")
#  expanding_window = function(){
monthly$yyyymm = monthly$yyyymm %>% as.character()
quart$yyyyq = quart$yyyyq %>% as.character()
annual$yyyy = annual$yyyy %>% as.character()
# Adding quarters to monthly
df = select(quart, -c(names(monthly)[-1], yyyyq)) %>%
slice(rep(1:n(), each=3)) %>%
apply(., MARGIN = 2, dplyr::lag, n=2) %>%
cbind(monthly, . ) %>% as_tibble
# Adding Annual (only the eqis variable is missing)
df$eqis = rep(annual$eqis, each=12) %>% lag(n=11)
# Gonna Remove cay, E3, D3, cause they dont really belong
df = select(df,-c(cay, D3, E3,csp))
#Now I have
names(df)
# Index"       "D12"        "E12"        "b/m"
# "tbl"        "AAA"        "BAA"
# "lty"        "ntis"       "Rfree"      "infl"
# "ltr"        "corpr"      "svar"
# "CRSP_SPvw"  "CRSP_SPvwx" "ik"         "eqis"
# Create a date variable
df$date = ymd(paste0(df$yyyymm, "01"))
## Creating new variables
df = mutate(df, dp = log(D12) - log(Index))
df = mutate(df, dy = log(D12) - lag(log(Index)))
df = mutate(df, ep = log(E12) - log(Index))
df = mutate(df, dfy = BAA - AAA)
df = mutate(df, dfr = corpr - ltr)
## The returns, notice timing is such that r_t+1 is next to p_t
df = mutate(df, r = c(diff(log(Index)), NA))
## Creating momentum variables
df$mom3 = c(rep(NA,3), embed(df$r, 4)[,2:4] %>% rowSums())
df$mom6 = c(rep(NA,6), embed(df$r, 7)[,2:7] %>% rowSums())
df$mom12 = c(rep(NA,12), embed(df$r, 13)[,2:13] %>% rowSums())
# full availability from 1947-03-01 , i/k not available before.
plot(df$date, complete.cases(df),type = "l")
# Saw off dataframe to omit all NA rows.
df = df[complete.cases(df),]
#So the sample runs from 1947-03-01 to 2017-06-01
## Now remove superflous variables so not to have multicoll
df = select(df, -c(date, Index, yyyymm, D12,
E12, AAA, BAA, corpr, CRSP_SPvwx,
CRSP_SPvw, Rfree))
df = select(df, r, everything())
names(df)[names(df)=="b/m"] = "bm"
names(df)
library(reshape2)
library(tidyverse)
library(abind)
library(glmnet)
library(pls)
library(lars)
library(mvtnorm)
library(gglasso)
library(splines)
library(leaps)
library(lubridate)
library(tree)
library(randomForest)
library(gbm)
library(Hmisc)
library(sandwich)
rm(list=ls())
library(readxl)
## Using PredictorData2017 from Amit Goyals' website (University of lausanne)
## data is from paper ("http://www.hec.unil.ch/agoyal/")
## "A Comprehensive Look at The Empirical Performance of Equity Premium Prediction"
## Data is updated up to 2017
monthly <-
read_excel("~/Dropbox/Project/PredictorData2017.xlsx" , sheet = "Monthly",
na = "NaN")
quart <-
read_excel("~/Dropbox/Project/PredictorData2017.xlsx" ,
sheet = "Quarterly",
na = "NaN")
annual <-
read_excel("~/Dropbox/Project/PredictorData2017.xlsx" , sheet = "Annual",
na = "NaN")
#  expanding_window = function(){
monthly$yyyymm = monthly$yyyymm %>% as.character()
quart$yyyyq = quart$yyyyq %>% as.character()
annual$yyyy = annual$yyyy %>% as.character()
# Adding quarters to monthly
df = select(quart, -c(names(monthly)[-1], yyyyq)) %>%
slice(rep(1:n(), each=3)) %>%
apply(., MARGIN = 2, dplyr::lag, n=2) %>%
cbind(monthly, . ) %>% as_tibble
# Adding Annual (only the eqis variable is missing)
df$eqis = rep(annual$eqis, each=12) %>% lag(n=11)
# Gonna Remove cay, E3, D3, cause they dont really belong
df = select(df,-c(cay, D3, E3,csp))
#Now I have
names(df)
# Index"       "D12"        "E12"        "b/m"
# "tbl"        "AAA"        "BAA"
# "lty"        "ntis"       "Rfree"      "infl"
# "ltr"        "corpr"      "svar"
# "CRSP_SPvw"  "CRSP_SPvwx" "ik"         "eqis"
# Create a date variable
df$date = ymd(paste0(df$yyyymm, "01"))
## Creating new variables
df = mutate(df, dp = log(D12) - log(Index))
df = mutate(df, dy = log(D12) - lag(log(Index)))
df = mutate(df, ep = log(E12) - log(Index))
df = mutate(df, dfy = BAA - AAA)
df = mutate(df, dfr = corpr - ltr)
## The returns, notice timing is such that r_t+1 is next to p_t
df = mutate(df, r = c(diff(log(Index)), NA))
## Creating momentum variables
df$mom3 = c(rep(NA,3), embed(df$r, 4)[,2:4] %>% rowSums())
df$mom6 = c(rep(NA,6), embed(df$r, 7)[,2:7] %>% rowSums())
df$mom12 = c(rep(NA,12), embed(df$r, 13)[,2:13] %>% rowSums())
# full availability from 1947-03-01 , i/k not available before.
plot(df$date, complete.cases(df),type = "l")
# Saw off dataframe to omit all NA rows.
df = df[complete.cases(df),]
#So the sample runs from 1947-03-01 to 2017-06-01
## Now remove superflous variables so not to have multicoll
df = select(df, -c(date, Index, yyyymm, D12,
E12, AAA, BAA, corpr, CRSP_SPvwx,
CRSP_SPvw, Rfree))
df = select(df, r, everything())
names(df)[names(df)=="b/m"] = "bm"
T= nrow(df)
df$time=1:T
df = as.data.frame(df)
initial_T=floor(T/2)
val_T=floor(T/4)
sample.size = T
test.sample = which(df$time>initial_T+val_T)
test.sample.size = length(test.sample)
train.sample = which(df$time<=initial_T + val_T)
historical.mean = mean(df$r[train.sample])
tot.test = mean((df$r[test.sample] - historical.mean)^2)
tot.test.no.demean = mean(df$r[test.sample]^2)
########################################################################
## FOr use in loop
########################################################################
lambda.grid = 10^seq(2,-5, length = 100)
# For Neural Network
build_model = function(layers=2, lr = 0.0001, lambda=lambda.grid.NN[i]){
## One layer
if (layers == 1){
model <- keras_model_sequential() %>%
layer_dense(units = 32,
kernel_regularizer = regularizer_l1(lambda),
input_shape = dim(x_train)[2]) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 1, kernel_regularizer = regularizer_l1(lambda))
}
if(layers == 2){
model <- keras_model_sequential() %>%
layer_dense(units = 32,
kernel_regularizer = regularizer_l1(lambda),
input_shape = dim(x_train)[2]) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 16,
kernel_regularizer = regularizer_l1(lambda)) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 1, kernel_regularizer = regularizer_l1(lambda))
}
if(layers == 3){
model <- keras_model_sequential() %>%
layer_dense(units = 32,
kernel_regularizer = regularizer_l1(lambda),
input_shape = dim(x_train)[2]) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 16,
kernel_regularizer = regularizer_l1(lambda)) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 8,
kernel_regularizer = regularizer_l1(lambda)) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 1, kernel_regularizer = regularizer_l1(lambda))
}
if(layers >= 4){
model <- keras_model_sequential() %>%
layer_dense(units = 32,
kernel_regularizer = regularizer_l1(lambda),
input_shape = dim(x_train)[2]) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 16,
kernel_regularizer = regularizer_l1(lambda)) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 8,
kernel_regularizer = regularizer_l1(lambda)) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 4,
kernel_regularizer = regularizer_l1(lambda)) %>%
layer_activation("relu") %>%
layer_batch_normalization() %>%
layer_dense(units = 1, kernel_regularizer = regularizer_l1(lambda))
}
model %>% compile(
loss = "mean_squared_error",
optimizer = optimizer_adam(lr = lr),
metrics = list("mean_absolute_error")
)
model
#End function
}
##Vectors for predictions
lm.pred = numeric(T)
ridge.pred = numeric(T)
lasso.pred = numeric(T)
enet.pred = numeric(T)
pcr.pred = numeric(T)
plsr.pred = numeric(T)
glm.pred = numeric(T)
randomF.pred = numeric(T)
boost.pred = numeric(T)
NN1.pred = numeric(T)
NN2.pred = numeric(T)
NN3.pred = numeric(T)
## Lists for model fits for each model
lm.list = list(0)
ridge.list = list(0)
lasso.list = list(0)
enet.list = list(0)
pcr.list = list(0)
plsr.list = list(0)
glm.list = list(0)
RF.list = list(0)
GBRT.list = list(0)
NN1.list = list(0)
NN2.list = list(0)
NN3.list = list(0)
########################################################################
################## ------- STARTING LOOP ----------- ###################
########################################################################
### Loop it over
seq = seq(initial_T, T - val_T -1, by = 12)
no.of.models = length(seq)
length(seq)
q =5
t = seq[q]
#The current window in terms of time index as well as the corresponding observations
test.window = seq(t+val_T+1, ifelse(t+val_T+12<= T, t+val_T+12, T) )
test.window.obs = which(df$time %in% test.window)
#Create the three samples for training, tuning and testing
train= df %>% filter(time %in% 1:t) %>% select(-time)
val= df %>% filter(time %in% (t+1):(t+val_T)) %>% select(-time)
test= df %>%
filter( time %in% test.window ) %>%
select(-time)
full.train = rbind(train,val)
df
df %>% colMeans()
colMeans(train)
?glmnet
library(reshape2)
library(tidyverse)
library(ISLR)
library(abind)
library(glmnet)
library(pls)
library(lars)
library(mvtnorm)
library(elasticnet)
Pc = 50
DGP = "a"
N=200
T=180
#Creating c_bar for firm characteristics.
rho_c=runif(n = Pc, min = 0.9, max = 1)
eps_c = rnorm(T*N*Pc)
dim(eps_c)=c(N,Pc,T)
c_bar=array(dim = c(N, Pc, T))
c=array(dim = c(N, Pc, T))
c_bar[,,1]=eps_c[,,1]
for (i in 1:N){
for (j in 1:Pc){
for (t in 2:T){
c_bar[i,j,t]=rho_c[j]*c_bar[i,j,t-1]+eps_c[i,j,t]
}
}
}
rank=rank(c(c_bar))
dim(rank)=c(N,Pc,T)
n=N*T*Pc
for (i in 1:N){
for (j in 1:Pc){
for (t in 1:T){
c[i,j,t] = 2*rank[i,j,t]/(n+1) -1
}
}
}
beta=c[,1:3,]
#Creating x, which is just a common timeseries. AR(1) no constant.
rho=0.95
u=rnorm(T+200, sd = 1-rho^2)
x=numeric(T+200)
x[1]=0
for (t in 2:(T+200)){
x[t]=rho*x[t-1]+u[t]
}
x=x[(length(x)-T+1):length(x)]
#Create vector z which is interaction of all x with c
c2=array(dim=dim(c))
for (t in 1:T){
c2[,,t]=x[t]*c[,,t]
}
z=abind(c,c2,along= 2)
#Finally create the returns from the characteristics
v=rmvnorm(n=T,mean = c(0,0,0),sigma = diag(0.05^2,3,3))
eps=rt(n = T*N,df = 5)*0.05
dim(eps)=c(N,T)
#There are two cases for the function g(z), case (a) and (b).
g=matrix(nrow = N,ncol = T)
#for (a)
if(DGP=="a"){
theta=c(rep(0.02,3))
for (i in 1:N){
for (t in 1:T){
g[i,t]=z[i,1,t]*theta[1]+z[i,2,t]*theta[2]+z[i,(Pc+3),t]*theta[3]
}
}
}
#for (b)
if(DGP=="b"){
theta=c(0.04,0.03,0.012)
g=matrix(nrow = N,ncol = T)
for (i in 1:N){
for (t in 1:T){
g[i,t]=z[i,1,t]^2*theta[1]+z[i,1,t]*z[i,2,t]*theta[2]+sign(z[i,(Pc+3),t]*theta[3])
}
}
}
#Finally we calculate the returns, one for dgp (a) and one for (b)
e=matrix(nrow = N,ncol = T)
for (i in 1:N){
for (t in 1:T){
e[i,t] = beta[i,,t]%*%v[t,]+eps[i,t]
}
}
#The response is thus
r=g+e
#Note that inputs range from period 1 to T and response ranges from 2 to
#T+1
#make inputs to a panel of data instead of 3d array
#likewise make response into vector instead of 2d array
#the rows are ordered st. all firms in one period are together
Y=c(r)
input <- lapply(seq_len(T), function(i) data.frame(z[,,i])) %>%
bind_rows(.)
df <- cbind(Y,input)
df$time = sapply(1:T, function(i) rep(i,N)) %>% c(.)
df$id=rep(1:N,T)
#df = df[ , c(53,52,1:51)]
train_T=T/2
val_T=train_T+T/4
train= df %>% filter(time %in% 1:train_T ) %>% select(-c(id, time))
val= df %>% filter(time %in% (train_T+1):val_T) %>% select(-c(id, time))
test= df %>% filter(time %in% (val_T+1):T) %>% select(-c(id,time))
all = rbind(train,val,test)
dim(all)
dim(all)[1]
as_tibble(all)
Pc
